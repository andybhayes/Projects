import requests
from bs4 import BeautifulSoup
import os


# URL of the website to scrape
url = "https://www.metoffice.gov.uk/research/climate/maps-and-data/historic-station-data"

# Send an HTTP GET request to the URL
response = requests.get(url)

# Check if the request was successful
if response.status_code == 200:
    # Parse the HTML content of the page
    soup = BeautifulSoup(response.text, "html.parser")

    # Find all links with "txt" in the href attribute
    txt_links = [link for link in soup.find_all("a") if link.get("href") and ".txt" in link["href"]]

    # Create a directory to save the downloaded files
    if not os.path.exists("downloaded_txt_files"):
        os.makedirs("downloaded_txt_files")

    # Loop through the links and download the data
    for link in txt_links:
        data_url = link["href"]
        data_response = requests.get(data_url)
        if data_response.status_code == 200:
            # Extract the filename from the URL
            filename = os.path.join("downloaded_txt_files", os.path.basename(data_url))
            # Save the data to a file
            with open(filename, "wb") as file:
                file.write(data_response.content)
            print(f"Downloaded: {filename}")
        else:
            print(f"Failed to download data from: {data_url}")
else:
    print("Failed to fetch the web page.")
